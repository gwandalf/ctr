\documentclass[a4paper]{article}

\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}

\title{Rapport CTR : Kd-Trees}

\author{Gwendal Le Moulec}

\date{\today}

\begin{document}

\section{Présentation des articles}

\subsection{Construction de kd-Trees en O(N log N)}

\textit{Cette sous-partie traite exclusivement de l'article} On building fast kd-Trees for Ray Tracing, and on doing that in O(N log N)\textit{, de Ingo Wald et Vlastimil Havran.}

L'article présente un algorithme permettant de construire des kd-Trees efficaces avec une complexité de $O(N.log(N))$. Les auteurs partent du constat qu'on cherche en général à construires des kd-Trees efficaces pour la recherche dans un espace à $k$ dimensions, sans prendre en compte le temps de construction du kd-Tree. Il est vrai que ceci n'est pas un gros problème pour des petits espaces. Cependant, les espaces deviennent de plus en plus grands et de plus en plus denses, ce qui met eu premier plan la nécessité de disposer d'algorithmes rapides. Or, la plupart des algorithmes utilisés aujourd'hui ont une complexité de $O(Nlog²N)$ ou même de $O(N²)$. Il est dit que la limite inférieure théoriquement atteignable est $O(N.log(N))$.

La proposition d'algorithme est tirée d'un algorithme en $O(N.log²(N))$ ré-adapté. Comme pour tous les algorithmes, de construction de kd-trees, ce qui est déterminant est la recherche du plan séparateur en chaque noeud. Pour ce faire, il faut trouver un plan aligné sur un des axes de la base du repère qui minimise le côut estimé de traversée des deux voxels. L'approche utilisée pour calculer ce coût est l'heuristique SAH\footnote{Surface Area Heuristique}. Le coût alors calculé est~:

%TODO formule du coût.

On doit considérer que pour un voxel de dimensions données et non coupé, son côut de traversée dépend uniquement du nombre de triangles qu'il contient.
Des considérations heuristiques permettent de définir un ensemble de plans candidats, à partir desquels sera choisi le plan minimisant le coût. L'idée de base pour trouver les candidats est de ne sélectionner que les plans qui délimitent les AABB\footnote{Axis Aligned Bounding Box} des triangles, car ce sont les endroits où le nombre de triangles change d'un c\^oté et de l'autre du plan, ce qui provoque des sauts dans la fonction de co\^ut. Les minimums sont donc à chercher à ces positions.

Puisque l'on veut connaître la complexité de nos algorithmes, commençons par identifier les grandes étapes d'un algorithme de construction d'un kd-tree. En pseudo-code, les fonctions de construction classiques dont on veut connaître la complexité suivent cet algorithme~:
\\\\
$$function Arbre(Triangles T, Voxel V)
	Si cas d'arrêt~:
		retourne Feuille(T)
	Plan p = TrouverPlan(T, V)
	Calcul de T_g, T_d, V_g et V_d en fonction de p
	retourne Nœud(p, Arbre(T_g, V_g), Arbre(T_d, V_d))$$
\\\\
Ceci nous amène à la formule de complexité suivante~:
\\\\
$T(N) = T_{TrouverPlan}(N) + 2T(\frac{N}{2})$
\\\\
où $N$ est le nombre de triangles. Le point déterminant sur lequel nous pouvons jouer est donc la fonction $TrouverPlan$. Conformément à ce qui est dit plus haut, nous devons trouver les plans candidats et calculer pour chacun d'entre eux le coût de traversée du voxel coupé. Le plan qui donne le coût minimal sera choisi. L'approche naïve donnerait l'algorithme suivant~:
\\\\
$$function TrouverPlan(Triangles T, Voxel V)
	entier min = MAX_INT
	Plan p_{res}
	Pour chaque triangle t de T~:
		P = {6 faces de l'AABB}
		Pour chaque plan p de P~:
			N_g = NbTrianglesAGauche(T, p)
			N_d = NbTrianglesADroite(T, p)
			N_p = NbTrianglesCoplanaires(T, p)
			coût = SAH(V, p, N_g, N_d)
			Si coût < min~:
				min = coût
				p_{res} = p
	retourne p_{res}$$
\\\\
Il est évident que la complexité des fonctions de comptage est de $O(N)$. La complexité totale de cette implémentation naïve de $TrouverPlan$ est donc de $O(N^2)$. Nous devrions réduire cette complexité. Les auteurs de l'article ont remarqué que le meilleur plan peut être trouvé en un temps linéaire. Le principe de base est le suivant~: pour une même dimension $x$, si on trie les plans selon leur position de gauche à droite, il devient facile de compter le nombre de triangles de chaque côté d'un plan récursivement~:
\begin{enumerate}
	\item $N_g^{(i)}$~: il ne peut qu'augmenter. Pour un plan $plan_i$, $N_g^{(i)}$ = $N_g^{(i-1)} + N_p^{(i-1)} + $ nombre de triangles "commençant" au plan $plan^{(i-1)}$
	\item $N_d^{(i)}$~: il ne peut que diminuer. Pour un plan $plan_i$, $N_d^{(i)}$ = $N_d^{(i-1)} - N_p^{(i)} - $ nombre de triangles "se terminant" au plan $plan_i$ 
	\item Pour tout $i$, $N_p^(i)$ doit \^etre calculé préalablement.
\end{enumerate}

En pratique, il n'est pas possible d'implémenter ces suites avec des simples tableaux. Les auteurs de l'article proposent de définir une nouvelle structure de données, l'événement, qui contient les trois champs suivants~:
\begin{enumerate}
	\item Triangle associé t
	\item Position du plan associé \epsilon
	\item Type $type$~: indique si t "commence", "se termine" ou est coplanaire au plan \epsilon. Ces types seront respectivement codés +, - et |.
\end{enumerate}

Pour une dimension $k$ donnée, on construira une liste $E$ d'événements de la manière suivante~: Pour chaque triangle $t$, on générera tous les événements associant ce triangle à un plan candidat "en contact" et on précisera la nature de ce contact (+, - ou |). Cette construction a une complexité temporelle de $O(N)$. Par soucis de concision, nous ne donnerons pas les détails du calcul ici. La liste $E$ devra ensuite être triée, ce qui donne une complexité de $O(NlogN)$ avec un tri rapide. Le critère de tri est le suivant~: soient deux événements $e_1$ = ($t_1$, $\epsilon_1$, $type_1$) et $e_2$ = ($t_2$, $\epsilon_2$, $type_2$). Si $\epsilon_1 \inf \epsilon_2$, alors $e_1 \inf e_2$. En cas d'égalité, on utilise un ordre arbitraire sur +, - et |. Les auteurs de l'article proposent - \inf | \inf +.

On remarque alors que tous les événements de même plan sont contigüs. On pourra alors virtuellement subdiviser la liste en groupes, chacun étiqueté par un plan.

Ceci nous permet de réécrire la fonction $TrouverPlan$~:
\\\\
$$function TrouverPlan(Triangles T, Voxel V)
	entier min = MAX_INT
	Plan p_{res}
	Pour k = 1, 2, 3~:
		E = InitListeEvenements(k, T, V)
		trier(E)
		N_g = 0, N_p = 0, N_d = taille(T)
		Pour tous les groupes g_{\epsilon} de E, pris dans l'ordre~:
			nb_-, nb_|, nb_+ = compterTypes(g_{\epsilon})
			%TODO : copié coller de l'article
	retourne p_{res}$$
\\\\

\subsection{A rédiger correctement...}
L'optimisation permettant d'atteindre O(NlogN) ne nécessite pas grand chose. En fait, il suffit de se rendre compte que sortie le tri des appels récursifs (la faire avant la construction de l'arbre), nous permet d'améliorer la complexité (Note pour moi m^eme : ne pas en dire plus que cela. L'idée c'est de juste mettre ne évidence le fait que cette petite astuce suffit).

Pour les tests on peut simplement commenter un peu et formuler les critiques suivantes :
(-) pas de comparaison avec d'autres approches (vérifier les dates et l'état de l'art)
(-) beaucoup de colonnes ne sont pas très intéressantes (N_l, N_r etc...)
(-) pas de scènes dynamiques

sur l'article :
(+) démonstration très complète et rigoureuse.
(~) pas d'utilisation du parallélisme (ce serait encore mieux)

autres remarques, en vrac :
Première impression est très positive : la démarche est très rigoureuse et du recul est pris par rapport aux (bons) résultats (expliquer). Le fait que l'algorithme ait prouvé sa valeur dans l'industrie est un argument solide en sa faveur. Dommage quand même que les résultats de performances des traversées des kd-trees ne soient pas présentés (c'est vrai que ce n'est pas le sujet de l'article mais c'est l'essentiel pour les kd-trees).
	Pas de comparaison en terme place de mémoire prise par les structures de données. Il serait intéressant d'avoir cette information (faire l'expérience pour connaitre cela et donner les conclusions).
	Part du principe que SAH est la meilleure approche. Existe-t-il d'autres approches reconnues plus rapides (mais certainement pas de meilleure complexité) ?
	La limite théorique de O(NlogN) n'est pas claire : il est dit que cela est dû au tri mais qui a dit que pour être "intelligent", il fallait absolument implémenter un tri ?
	
%TODO faire des recherches pour appuyer / infirmer ces critiques, tirer des critiques de la mise en oeuvre pratique.

\section{Some \LaTeX{} Examples}
\label{sec:examples}

\subsection{How to Leave Comments}

Comments can be added to the margins of the document using the \todo{Here's a comment in the margin!} todo command, as shown in the example on the right. You can also add inline comments:

\todo[inline, color=green!40]{This is an inline comment.}

\subsection{How to Include Figures}

First you have to upload the image file (JPEG, PNG or PDF) from your computer to writeLaTeX using the upload link the project menu. Then use the includegraphics command to include it in your document. Use the figure environment and the caption command to add a number and a caption to your figure. See the code for Figure \ref{fig:frog} in this section for an example.

%\begin{figure}
%\centering
%\includegraphics[width=0.3\textwidth]{frog.jpg}
%\caption{\label{fig:frog}This frog was uploaded to writeLaTeX via the project menu.}
%\end{figure}

\subsection{How to Make Tables}

Use the table and tabular commands for basic tables --- see Table~\ref{tab:widgets}, for example.

\begin{table}
\centering
\begin{tabular}{l|r}
Item & Quantity \\\hline
Widgets & 42 \\
Gadgets & 13
\end{tabular}
\caption{\label{tab:widgets}An example table.}
\end{table}

\subsection{How to Write Mathematics}

\LaTeX{} is great at typesetting mathematics. Let $X_1, X_2, \ldots, X_n$ be a sequence of independent and identically distributed random variables with $\text{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$, and let
$$S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}
      = \frac{1}{n}\sum_{i}^{n} X_i$$
denote their mean. Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n - \mu)$ converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$.

\subsection{How to Make Sections and Subsections}

Use section and subsection commands to organize your document. \LaTeX{} handles all the formatting and numbering automatically. Use ref and label commands for cross-references.

\subsection{How to Make Lists}

You can make lists with automatic numbering \dots

\begin{enumerate}
\item Like this,
\item and like this.
\end{enumerate}
\dots or bullet points \dots
\begin{itemize}
\item Like this,
\item and like this.
\end{itemize}
\dots or with words and descriptions \dots
\begin{description}
\item[Word] Definition
\item[Concept] Explanation
\item[Idea] Text
\end{description}

We hope you find write\LaTeX\ useful, and please let us know if you have any feedback using the help menu above.

\end{document}